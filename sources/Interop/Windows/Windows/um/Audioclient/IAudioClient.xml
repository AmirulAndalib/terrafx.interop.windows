<?xml version="1.0" encoding="utf-8"?>
<!-- Copyright © Tanner Gooding and Contributors. Licensed under the MIT License (MIT). See License.md in the repository root for more information. -->
<!-- Ported from https://github.com/MicrosoftDocs/sdk-api/ -->
<doc>
  <member name="IAudioClient.GetBufferSize">
    <summary>
      <para>The <b>GetBufferSize</b> method retrieves the size (maximum capacity) of the endpoint buffer.</para>
    </summary>
    <param name="pNumBufferFrames">
      <para>Pointer to a <b>UINT32</b> variable into which the method writes the number of audio frames that the buffer can hold.</para>
    </param>
    <returns>
      <para>If the method succeeds, it returns S_OK. If it fails, possible return codes include, but are not limited to, the values shown in the following table.</para>
      <list type="table">
        <listheader>
          <description>Return code</description>
          <description>Description</description>
        </listheader>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_NOT_INITIALIZED</b>
            </para>
          </description>
          <description>
            <para>The audio stream has not been successfully initialized.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_DEVICE_INVALIDATED</b>
            </para>
          </description>
          <description>
            <para>The audio endpoint device has been unplugged, or the audio hardware or associated hardware resources have been reconfigured, disabled, removed, or otherwise made unavailable for use.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_SERVICE_NOT_RUNNING</b>
            </para>
          </description>
          <description>
            <para>The Windows audio service is not running.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>E_POINTER</b>
            </para>
          </description>
          <description>
            <para>Parameter <i>pNumBufferFrames</i> is <b>NULL</b>.</para>
          </description>
        </item>
      </list>
    </returns>
    <remarks>
      <para>This method requires prior initialization of the <see cref="IAudioClient" /> interface. All calls to this method will fail with the error AUDCLNT_E_NOT_INITIALIZED until the client initializes the audio stream by successfully calling the <see cref="IAudioClient.Initialize" /> method.</para>
      <para>This method retrieves the length of the endpoint buffer shared between the client application and the audio engine. The length is expressed as the number of audio frames the buffer can hold. The size in bytes of an audio frame is calculated as the number of channels in the stream multiplied by the sample size per channel. For example, the frame size is four bytes for a stereo (2-channel) stream with 16-bit samples.</para>
      <para>The <see cref="IAudioClient.Initialize" /> method allocates the buffer. The client specifies the buffer length in the <i>hnsBufferDuration</i> parameter value that it passes to the <b>Initialize</b> method. For rendering clients, the buffer length determines the maximum amount of rendering data that the application can write to the endpoint buffer during a single processing pass. For capture clients, the buffer length determines the maximum amount of capture data that the audio engine can read from the endpoint buffer during a single processing pass. The client should always call <b>GetBufferSize</b> after calling <b>Initialize</b> to determine the actual size of the allocated buffer, which might differ from the requested size.</para>
      <para>Rendering clients can use this value to calculate the largest rendering buffer size that can be requested from <see cref="IAudioRenderClient.GetBuffer" /> during each processing pass.</para>
      <para>For code examples that call the <b>GetBufferSize</b> method, see the following topics:</para>
      <list type="bullet">
        <item>
          <description>
            <a href="https://docs.microsoft.com//windows/desktop/CoreAudio/rendering-a-stream">Rendering a Stream</a>
          </description>
        </item>
        <item>
          <description>
            <a href="https://docs.microsoft.com//windows/desktop/CoreAudio/capturing-a-stream">Capturing a Stream</a>
          </description>
        </item>
      </list>
    </remarks>
    <seealso cref="IAudioClient Interface" />
    <seealso cref="IAudioClient.Initialize" />
    <seealso cref="IAudioRenderClient.GetBuffer" />
  </member>
  <member name="IAudioClient.GetCurrentPadding">
    <summary>
      <para>The <b>GetCurrentPadding</b> method retrieves the number of frames of padding in the endpoint buffer.</para>
    </summary>
    <param name="pNumPaddingFrames">
      <para>Pointer to a <b>UINT32</b> variable into which the method writes the frame count (the number of audio frames of padding in the buffer).</para>
    </param>
    <returns>
      <para>If the method succeeds, it returns S_OK. If it fails, possible return codes include, but are not limited to, the values shown in the following table.</para>
      <list type="table">
        <listheader>
          <description>Return code</description>
          <description>Description</description>
        </listheader>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_NOT_INITIALIZED</b>
            </para>
          </description>
          <description>
            <para>The audio stream has not been successfully initialized.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_DEVICE_INVALIDATED</b>
            </para>
          </description>
          <description>
            <para>The audio endpoint device has been unplugged, or the audio hardware or associated hardware resources have been reconfigured, disabled, removed, or otherwise made unavailable for use.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_SERVICE_NOT_RUNNING</b>
            </para>
          </description>
          <description>
            <para>The Windows audio service is not running.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>E_POINTER</b>
            </para>
          </description>
          <description>
            <para>Parameter <i>pNumPaddingFrames</i> is <b>NULL</b>.</para>
          </description>
        </item>
      </list>
    </returns>
    <remarks>
      <para>This method requires prior initialization of the <see cref="IAudioClient" /> interface. All calls to this method will fail with the error AUDCLNT_E_NOT_INITIALIZED until the client initializes the audio stream by successfully calling the <see cref="IAudioClient.Initialize" /> method.</para>
      <para>This method retrieves a padding value that indicates the amount of valid, unread data that the endpoint buffer currently contains. A rendering application can use the padding value to determine how much new data it can safely write to the endpoint buffer without overwriting previously written data that the audio engine has not yet read from the buffer. A capture application can use the padding value to determine how much new data it can safely read from the endpoint buffer without reading invalid data from a region of the buffer to which the audio engine has not yet written valid data.</para>
      <para>The padding value is expressed as a number of audio frames. The size of an audio frame is specified by the <b>nBlockAlign</b> member of the <see cref="WAVEFORMATEX" /> (or <a href="https://docs.microsoft.com//windows-hardware/drivers/ddi/content/ksmedia/ns-ksmedia-waveformatextensible">WAVEFORMATEXTENSIBLE</a>) structure that the client passed to the <see cref="IAudioClient.Initialize" />  method. The size in bytes of an audio frame equals the number of channels in the stream multiplied by the sample size per channel. For example, the frame size is four bytes for a stereo (2-channel) stream with 16-bit samples.</para>
      <para>For a shared-mode rendering stream, the padding value reported by <b>GetCurrentPadding</b> specifies the number of audio frames that are queued up to play in the endpoint buffer. Before writing to the endpoint buffer, the client can calculate the amount of available space in the buffer by subtracting the padding value from the buffer length. To ensure that a subsequent call to the <see cref="IAudioRenderClient.GetBuffer" /> method succeeds, the client should request a packet length that does not exceed the available space in the buffer. To obtain the buffer length, call the <see cref="IAudioClient.GetBufferSize" /> method.</para>
      <para>For a shared-mode capture stream, the padding value reported by <b>GetCurrentPadding</b> specifies the number of frames of capture data that are available in the next packet in the endpoint buffer. At a particular moment, zero, one, or more packets of capture data might be ready for the client to read from the buffer. If no packets are currently available, the method reports a padding value of 0. Following the <b>GetCurrentPadding</b> call, an <see cref="IAudioCaptureClient.GetBuffer" /> method call will retrieve a packet whose length exactly equals the padding value reported by <b>GetCurrentPadding</b>. Each call to <see cref="GetBuffer" /> retrieves a whole packet. A packet always contains an integral number of audio frames.</para>
      <para>For a shared-mode capture stream, calling <b>GetCurrentPadding</b> is equivalent to calling the <see cref="IAudioCaptureClient.GetNextPacketSize" /> method. That is, the padding value reported by <b>GetCurrentPadding</b> is equal to the packet length reported by <b>GetNextPacketSize</b>.</para>
      <para>For an exclusive-mode rendering or capture stream that was initialized with the AUDCLNT_STREAMFLAGS_EVENTCALLBACK flag, the client typically has no use for the padding value reported by <b>GetCurrentPadding</b>. Instead, the client accesses an entire buffer during each processing pass. Each time a buffer becomes available for processing, the audio engine notifies the client by signaling the client's event handle. For more information about this flag, see <see cref="IAudioClient.Initialize" />.</para>
      <para>For an exclusive-mode rendering or capture stream that was not initialized with the AUDCLNT_STREAMFLAGS_EVENTCALLBACK flag, the client can use the padding value obtained from <b>GetCurrentPadding</b> in a way that is similar to that described previously for a shared-mode stream. The details are as follows.</para>
      <para>First, for an exclusive-mode rendering stream, the padding value specifies the number of audio frames that are queued up to play in the endpoint buffer. As before, the client can calculate the amount of available space in the buffer by subtracting the padding value from the buffer length.</para>
      <para>Second, for an exclusive-mode capture stream, the padding value reported by <b>GetCurrentPadding</b> specifies the current length of the next packet. However, this padding value is a snapshot of the packet length, which might increase before the client calls the <see cref="IAudioCaptureClient.GetBuffer" /> method. Thus, the length of the packet retrieved by <b>GetBuffer</b> is at least as large as, but might be larger than, the padding value reported by the <b>GetCurrentPadding</b> call that preceded the <b>GetBuffer</b> call. In contrast, for a shared-mode capture stream, the length of the packet obtained from <b>GetBuffer</b> always equals the padding value reported by the preceding <b>GetCurrentPadding</b> call.</para>
      <para>For a code example that calls the <b>GetCurrentPadding</b> method, see <a href="https://docs.microsoft.com//windows/desktop/CoreAudio/rendering-a-stream">Rendering a Stream</a>.</para>
    </remarks>
    <seealso cref="IAudioCaptureClient.GetBuffer" />
    <seealso cref="IAudioCaptureClient.GetNextPacketSize" />
    <seealso cref="IAudioClient Interface" />
    <seealso cref="IAudioClient.Initialize" />
    <seealso cref="IAudioRenderClient.GetBuffer" />
  </member>
  <member name="IAudioClient.GetDevicePeriod">
    <summary>
      <para>The <b>GetDevicePeriod</b> method retrieves the length of the periodic interval separating successive processing passes by the audio engine on the data in the endpoint buffer.</para>
    </summary>
    <param name="phnsDefaultDevicePeriod">
      <para>Pointer to a <a href="https://docs.microsoft.com//windows/desktop/DirectShow/reference-time">REFERENCE_TIME</a> variable into which the method writes a time value specifying the default interval between periodic processing passes by the audio engine. The time is expressed in 100-nanosecond units. For information about <b>REFERENCE_TIME</b>, see the Windows SDK documentation.</para>
    </param>
    <param name="phnsMinimumDevicePeriod">
      <para>Pointer to a <a href="https://docs.microsoft.com//windows/desktop/DirectShow/reference-time">REFERENCE_TIME</a> variable into which the method writes a time value specifying the minimum interval between periodic processing passes by the audio endpoint device. The time is expressed in 100-nanosecond units.</para>
    </param>
    <returns>
      <para>If the method succeeds, it returns S_OK. If it fails, possible return codes include, but are not limited to, the values shown in the following table.</para>
      <list type="table">
        <listheader>
          <description>Return code</description>
          <description>Description</description>
        </listheader>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_DEVICE_INVALIDATED</b>
            </para>
          </description>
          <description>
            <para>The audio endpoint device has been unplugged, or the audio hardware or associated hardware resources have been reconfigured, disabled, removed, or otherwise made unavailable for use.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_SERVICE_NOT_RUNNING</b>
            </para>
          </description>
          <description>
            <para>The Windows audio service is not running.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>E_POINTER</b>
            </para>
          </description>
          <description>
            <para>Parameters <i>phnsDefaultDevicePeriod</i> and <i>phnsMinimumDevicePeriod</i> are both <b>NULL</b>.</para>
          </description>
        </item>
      </list>
    </returns>
    <remarks>
      <para>The client can call this method before calling the <see cref="IAudioClient.Initialize" /> method.</para>
      <para>The <i>phnsDefaultDevicePeriod</i> parameter specifies the default scheduling period for a shared-mode stream. The <i>phnsMinimumDevicePeriod</i> parameter specifies the minimum scheduling period for an exclusive-mode stream.</para>
      <para>At least one of the two parameters, <i>phnsDefaultDevicePeriod</i> and <i>phnsMinimumDevicePeriod</i>, must be non-<b>NULL</b> or the method returns immediately with error code E_POINTER. If both parameters are non-<b>NULL</b>, then the method outputs both the default and minimum periods.</para>
      <para>For a shared-mode stream, the audio engine periodically processes the data in the endpoint buffer, which the engine shares with the client application. The engine schedules itself to perform these processing passes at regular intervals.</para>
      <para>The period between processing passes by the audio engine is fixed for a particular audio endpoint device and represents the smallest processing quantum for the audio engine. This period plus the stream latency between the buffer and endpoint device represents the minimum possible latency that an audio application can achieve.</para>
      <para>The client has the option of scheduling its periodic processing thread to run at the same time interval as the audio engine. In this way, the client can achieve the smallest possible latency for a shared-mode stream. However, in an application for which latency is less important, the client can reduce the process-switching overhead on the CPU by scheduling its processing passes to occur less frequently. In this case, the endpoint buffer must be proportionally larger to compensate for the longer period between processing passes.</para>
      <para>The client determines the buffer size during its call to the <see cref="IAudioClient.Initialize" /> method. For a shared-mode stream, if the client passes this method an <i>hnsBufferDuration</i> parameter value of 0, the method assumes that the periods for the client and audio engine are guaranteed to be equal, and the method will allocate a buffer small enough to achieve the minimum possible latency. (In fact, any <i>hnsBufferDuration</i> value between 0 and the sum of the audio engine's period and device latency will have the same result.) Similarly, for an exclusive-mode stream, if the client sets <i>hnsBufferDuration</i> to 0, the method assumes that the period of the client is set to the minimum period of the audio endpoint device, and the method will allocate a buffer small enough to achieve the minimum possible latency.</para>
      <para>If the client chooses to run its periodic processing thread less often, at the cost of increased latency, it can do so as long as it creates an endpoint buffer during the <see cref="IAudioClient.Initialize" /> call that is sufficiently large.</para>
    </remarks>
    <seealso cref="IAudioClient Interface" />
    <seealso cref="IAudioClient.Initialize" />
  </member>
  <member name="IAudioClient.GetMixFormat">
    <summary>
      <para>The <b>GetMixFormat</b> method retrieves the stream format that the audio engine uses for its internal processing of shared-mode streams.</para>
    </summary>
    <param name="ppDeviceFormat">
      <para>Pointer to a pointer variable into which the method writes the address of the mix format. This parameter must be a valid, non-<b>NULL</b> pointer to a pointer variable. The method writes the address of a <b>WAVEFORMATEX</b> (or <b>WAVEFORMATEXTENSIBLE</b>) structure to this variable. The method allocates the storage for the structure. The caller is responsible for freeing the storage, when it is no longer needed, by calling the <b>CoTaskMemFree</b> function. If the <b>GetMixFormat</b> call fails, <i>*ppDeviceFormat</i> is <b>NULL</b>. For information about <b>WAVEFORMATEX</b>, <b>WAVEFORMATEXTENSIBLE</b>, and <b>CoTaskMemFree</b>, see the Windows SDK documentation.</para>
    </param>
    <returns>
      <para>If the method succeeds, it returns S_OK. If it fails, possible return codes include, but are not limited to, the values shown in the following table.</para>
      <list type="table">
        <listheader>
          <description>Return code</description>
          <description>Description</description>
        </listheader>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_DEVICE_INVALIDATED</b>
            </para>
          </description>
          <description>
            <para>The audio endpoint device has been unplugged, or the audio hardware or associated hardware resources have been reconfigured, disabled, removed, or otherwise made unavailable for use.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_SERVICE_NOT_RUNNING</b>
            </para>
          </description>
          <description>
            <para>The Windows audio service is not running.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>E_POINTER</b>
            </para>
          </description>
          <description>
            <para>Parameter <i>ppDeviceFormat</i> is <b>NULL</b>.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>E_OUTOFMEMORY</b>
            </para>
          </description>
          <description>
            <para>Out of memory.</para>
          </description>
        </item>
      </list>
    </returns>
    <remarks>
      <para>The client can call this method before calling the <see cref="IAudioClient.Initialize" /> method. When creating a shared-mode stream for an audio endpoint device, the <b>Initialize</b> method always accepts the stream format obtained from a <b>GetMixFormat</b> call on the same device.</para>
      <para>The mix format is the format that the audio engine uses internally for digital processing of shared-mode streams. This format is not necessarily a format that the audio endpoint device supports. Thus, the caller might not succeed in creating an exclusive-mode stream with a format obtained by calling <b>GetMixFormat</b>.</para>
      <para>For example, to facilitate digital audio processing, the audio engine might use a mix format that represents samples as floating-point values. If the device supports only integer PCM samples, then the engine converts the samples to or from integer PCM values at the connection between the device and the engine. However, to avoid resampling, the engine might use a mix format with a sample rate that the device supports.</para>
      <para>To determine whether the <b>Initialize</b> method can create a shared-mode or exclusive-mode stream with a particular format, call the <see cref="IAudioClient.IsFormatSupported" /> method.</para>
      <para>By itself, a <b>WAVEFORMATEX</b> structure cannot specify the mapping of channels to speaker positions. In addition, although <b>WAVEFORMATEX</b> specifies the size of the container for each audio sample, it cannot specify the number of bits of precision in a sample (for example, 20 bits of precision in a 24-bit container). However, the <b>WAVEFORMATEXTENSIBLE</b> structure can specify both the mapping of channels to speakers and the number of bits of precision in each sample. For this reason, the <b>GetMixFormat</b> method retrieves a format descriptor that is in the form of a <b>WAVEFORMATEXTENSIBLE</b> structure instead of a standalone <b>WAVEFORMATEX</b> structure. Through the <i>ppDeviceFormat</i> parameter, the method outputs a pointer to the <b>WAVEFORMATEX</b> structure that is embedded at the start of this <b>WAVEFORMATEXTENSIBLE</b> structure. For more information about <b>WAVEFORMATEX</b> and <b>WAVEFORMATEXTENSIBLE</b>, see the Windows DDK documentation.</para>
      <para>For more information about the <b>GetMixFormat</b> method, see <a href="https://docs.microsoft.com//windows/desktop/CoreAudio/device-formats">Device Formats</a>. For code examples that call <b>GetMixFormat</b>, see the following topics:</para>
      <list type="bullet">
        <item>
          <description>
            <a href="https://docs.microsoft.com//windows/desktop/CoreAudio/rendering-a-stream">Rendering a Stream</a>
          </description>
        </item>
        <item>
          <description>
            <a href="https://docs.microsoft.com//windows/desktop/CoreAudio/capturing-a-stream">Capturing a Stream</a>
          </description>
        </item>
      </list>
    </remarks>
    <seealso cref="IAudioClient Interface" />
    <seealso cref="IAudioClient.Initialize" />
    <seealso cref="IAudioClient.IsFormatSupported" />
  </member>
  <member name="IAudioClient.GetService">
    <summary>
      <para>The <b>GetService</b> method accesses additional services from the audio client object.</para>
    </summary>
    <param name="riid">
      <para>The interface ID for the requested service. The client should set this parameter to one of the following REFIID values:</para>
      <para>IID_IAudioCaptureClient</para>
      <para>IID_IAudioClientDuckingControl</para>
      <para>IID_IAudioClock</para>
      <para>IID_IAudioRenderClient</para>
      <para>IID_IAudioSessionControl</para>
      <para>IID_IAudioStreamVolume</para>
      <para>IID_IChannelAudioVolume</para>
      <para>IID_IMFTrustedOutput</para>
      <para>IID_ISimpleAudioVolume</para>
      <para>For more information, see Remarks.</para>
    </param>
    <param name="ppv">
      <para>Pointer to a pointer variable into which the method writes the address of an instance of the requested interface. Through this method, the caller obtains a counted reference to the interface. The caller is responsible for releasing the interface, when it is no longer needed, by calling the interface's <b>Release</b> method. If the <b>GetService</b> call fails, <i>*ppv</i> is <b>NULL</b>.</para>
    </param>
    <returns>
      <para>If the method succeeds, it returns S_OK. If it fails, possible return codes include, but are not limited to, the values shown in the following table.</para>
      <list type="table">
        <listheader>
          <description>Return code</description>
          <description>Description</description>
        </listheader>
        <item>
          <description>
            <para>
              <b>E_POINTER</b>
            </para>
          </description>
          <description>
            <para>Parameter <i>ppv</i> is <b>NULL</b>.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>E_NOINTERFACE</b>
            </para>
          </description>
          <description>
            <para>The requested interface is not available.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_NOT_INITIALIZED</b>
            </para>
          </description>
          <description>
            <para>The audio stream has not been initialized.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_WRONG_ENDPOINT_TYPE</b>
            </para>
          </description>
          <description>
            <para>The caller tried to access an <see cref="IAudioCaptureClient" /> interface on a rendering endpoint, or an <see cref="IAudioRenderClient" /> interface on a capture endpoint.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_DEVICE_INVALIDATED</b>
            </para>
          </description>
          <description>
            <para>The audio endpoint device has been unplugged, or the audio hardware or associated hardware resources have been reconfigured, disabled, removed, or otherwise made unavailable for use.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_SERVICE_NOT_RUNNING</b>
            </para>
          </description>
          <description>
            <para>The Windows audio service is not running.</para>
          </description>
        </item>
      </list>
    </returns>
    <remarks>
      <para>This method requires prior initialization of the <see cref="IAudioClient" /> interface. All calls to this method will fail with the error AUDCLNT_E_NOT_INITIALIZED until the client initializes the audio stream by successfully calling the <see cref="IAudioClient.Initialize" /> method.</para>
      <para>The <b>GetService</b> method supports the following service interfaces:</para>
      <list type="bullet">
        <item>
          <description>
            <see cref="IAudioCaptureClient" />
          </description>
        </item>
        <item>
          <description>
            <see cref="IAudioClock" />
          </description>
        </item>
        <item>
          <description>
            <see cref="IAudioRenderClient" />
          </description>
        </item>
        <item>
          <description>
            <see cref="IAudioSessionControl" />
          </description>
        </item>
        <item>
          <description>
            <see cref="IAudioStreamVolume" />
          </description>
        </item>
        <item>
          <description>
            <see cref="IChannelAudioVolume" />
          </description>
        </item>
        <item>
          <description>
            <see cref="IMFTrustedOutput" />
          </description>
        </item>
        <item>
          <description>
            <see cref="ISimpleAudioVolume" />
          </description>
        </item>
      </list>
      <para>In Windows 7, a new service identifier, <b>IID_IMFTrustedOutput</b>, has been added that facilitates the use of output trust authority (OTA) objects. These objects can operate inside or outside the Media Foundation's protected media path (PMP) and send content outside the Media Foundation pipeline. If the caller is outside PMP, then the OTA may not operate in the PMP,  and the protection settings are less robust. OTAs must implement the <see cref="IMFTrustedOutput" /> interface.
By passing <b>IID_IMFTrustedOutput</b> in <b>GetService</b>, an application can retrieve a pointer to the object's <b>IMFTrustedOutput</b> interface. For more information about protected objects and <b>IMFTrustedOutput</b>, see "Protected Media Path" in  the Media Foundation SDK documentation.</para>
      <para>For information about using trusted audio drivers in OTAs, see <a href="https://docs.microsoft.com//windows/desktop/CoreAudio/protected-user-mode-audio--puma-">Protected User Mode Audio (PUMA)</a>.</para>
      <para>Note that activating IMFTrustedOutput through this mechanism works regardless of whether the caller is running in PMP. However, if the caller is not running in a protected process (that is, the caller is not within Media Foundation's PMP) then the audio OTA might not operate in the PMP and the protection settings are less robust.</para>
      <para>To obtain the interface ID for a service interface, use the <b>__uuidof</b> operator. For example, the interface ID of <b>IAudioCaptureClient</b> is defined as follows:</para>
      <code>
const IID IID_IAudioCaptureClient  __uuidof(IAudioCaptureClient)

</code>
      <para>For information about the <b>__uuidof</b> operator, see the Windows SDK documentation.</para>
      <para>To release the <b>IAudioClient</b> object and free all its associated resources, the client must release all references to any service objects that were created by calling <b>GetService</b>, in addition to calling <b>Release</b> on the <b>IAudioClient</b> interface itself. The client must release a service from the same thread that releases the <b>IAudioClient</b> object.</para>
      <para>The <b>IAudioSessionControl</b>, <b>IAudioStreamVolume</b>, <b>IChannelAudioVolume</b>, and <b>ISimpleAudioVolume</b> interfaces control and monitor aspects of audio sessions and shared-mode streams. These interfaces do not work with exclusive-mode streams.</para>
      <para>For code examples that call the <b>GetService</b> method, see the following topics:</para>
      <list type="bullet">
        <item>
          <description>
            <a href="https://docs.microsoft.com//windows/desktop/CoreAudio/rendering-a-stream">Rendering a Stream</a>
          </description>
        </item>
        <item>
          <description>
            <a href="https://docs.microsoft.com//windows/desktop/CoreAudio/capturing-a-stream">Capturing a Stream</a>
          </description>
        </item>
      </list>
    </remarks>
    <seealso cref="IAudioCaptureClient Interface" />
    <seealso cref="IAudioClient Interface" />
    <seealso cref="IAudioClient.Initialize" />
    <seealso cref="IAudioClock Interface" />
    <seealso cref="IAudioRenderClient Interface" />
    <seealso cref="IAudioSessionControl Interface" />
    <seealso cref="IAudioStreamVolume Interface" />
    <seealso cref="IChannelAudioVolume Interface" />
    <seealso cref="ISimpleAudioVolume Interface" />
  </member>
  <member name="IAudioClient.GetStreamLatency">
    <summary>
      <para>The <b>GetStreamLatency</b> method retrieves the maximum latency for the current stream and can be called any time after the stream has been initialized.</para>
    </summary>
    <param name="phnsLatency">
      <para>Pointer to a <a href="https://docs.microsoft.com//windows/desktop/DirectShow/reference-time">REFERENCE_TIME</a> variable into which the method writes a time value representing the latency. The time is expressed in 100-nanosecond units. For more information about <b>REFERENCE_TIME</b>, see the Windows SDK documentation.</para>
    </param>
    <returns>
      <para>If the method succeeds, it returns S_OK. If it fails, possible return codes include, but are not limited to, the values shown in the following table.</para>
      <list type="table">
        <listheader>
          <description>Return code</description>
          <description>Description</description>
        </listheader>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_NOT_INITIALIZED</b>
            </para>
          </description>
          <description>
            <para>The audio stream has not been successfully initialized.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_DEVICE_INVALIDATED</b>
            </para>
          </description>
          <description>
            <para>The audio endpoint device has been unplugged, or the audio hardware or associated hardware resources have been reconfigured, disabled, removed, or otherwise made unavailable for use.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_SERVICE_NOT_RUNNING</b>
            </para>
          </description>
          <description>
            <para>The Windows audio service is not running.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>E_POINTER</b>
            </para>
          </description>
          <description>
            <para>Parameter <i>phnsLatency</i> is <b>NULL</b>.</para>
          </description>
        </item>
      </list>
    </returns>
    <remarks>
      <para>This method requires prior initialization of the <see cref="IAudioClient" /> interface. All calls to this method will fail with the error AUDCLNT_E_NOT_INITIALIZED until the client initializes the audio stream by successfully calling the <see cref="IAudioClient.Initialize" /> method.</para>
      <para>This method retrieves the maximum latency for the current stream. The value will not change for the lifetime of the <see cref="IAudioClient" /> object.</para>
      <para>Rendering clients can use this latency value to compute the minimum amount of data that they can write during any single processing pass. To write less than this minimum is to risk introducing glitches into the audio stream. For more information, see <see cref="IAudioRenderClient.GetBuffer" />.</para>
    </remarks>
    <seealso cref="IAudioClient Interface" />
    <seealso cref="IAudioClient.Initialize" />
    <seealso cref="IAudioRenderClient.GetBuffer" />
  </member>
  <member name="IAudioClient.IsFormatSupported">
    <summary>
      <para>The <b>IsFormatSupported</b> method indicates whether the audio endpoint device supports a particular stream format.</para>
    </summary>
    <param name="ShareMode">
      <para>The sharing mode for the stream format. Through this parameter, the client indicates whether it wants to use the specified format in exclusive mode or shared mode. The client should set this parameter to one of the following <see cref="AUDCLNT_SHAREMODE" /> enumeration values:</para>
      <para>AUDCLNT_SHAREMODE_EXCLUSIVE</para>
      <para>AUDCLNT_SHAREMODE_SHARED</para>
    </param>
    <param name="pFormat">
      <para>Pointer to the specified stream format. This parameter points to a caller-allocated format descriptor of type <b>WAVEFORMATEX</b> or <b>WAVEFORMATEXTENSIBLE</b>. The client writes a format description to this structure before calling this method. For information about <b>WAVEFORMATEX</b> and <b>WAVEFORMATEXTENSIBLE</b>, see the Windows DDK documentation.</para>
    </param>
    <param name="ppClosestMatch">
      <para>Pointer to a pointer variable into which the method writes the address of a <b>WAVEFORMATEX</b> or <b>WAVEFORMATEXTENSIBLE</b> structure. This structure specifies the supported format that is closest to the format that the client specified through the <i>pFormat</i> parameter. For shared mode (that is, if the <i>ShareMode</i> parameter is AUDCLNT_SHAREMODE_SHARED), set <i>ppClosestMatch</i> to point to a valid, non-<b>NULL</b> pointer variable. For exclusive mode, set <i>ppClosestMatch</i> to <b>NULL</b>. The method allocates the storage for the structure. The caller is responsible for freeing the storage, when it is no longer needed, by calling the <b>CoTaskMemFree</b> function. If the <b>IsFormatSupported</b> call fails and <i>ppClosestMatch</i> is non-<b>NULL</b>, the method sets <i>*ppClosestMatch</i> to <b>NULL</b>. For information about <b>CoTaskMemFree</b>, see the Windows SDK documentation.</para>
    </param>
    <returns>
      <list type="table">
        <listheader>
          <description>Return code</description>
          <description>Description</description>
        </listheader>
        <item>
          <description>
            <para>
              <b>S_OK</b>
            </para>
          </description>
          <description>
            <para>Succeeded and the audio endpoint device supports the specified stream format.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>S_FALSE</b>
            </para>
          </description>
          <description>
            <para>Succeeded with  a closest match to the specified format.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_UNSUPPORTED_FORMAT</b>
            </para>
          </description>
          <description>
            <para>Succeeded but the specified format is not supported in exclusive mode.</para>
          </description>
        </item>
      </list>
      <para>If the operation fails, possible return codes include, but are not limited to, the values shown in the following table.</para>
      <list type="table">
        <listheader>
          <description>Return code</description>
          <description>Description</description>
        </listheader>
        <item>
          <description>
            <para>
              <b>E_POINTER</b>
            </para>
          </description>
          <description>
            <para>Parameter <i>pFormat</i> is <b>NULL</b>, or <i>ppClosestMatch</i> is <b>NULL</b> and <i>ShareMode</i> is AUDCLNT_SHAREMODE_SHARED.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>E_INVALIDARG</b>
            </para>
          </description>
          <description>
            <para>Parameter <i>ShareMode</i> is a value other than AUDCLNT_SHAREMODE_SHARED or AUDCLNT_SHAREMODE_EXCLUSIVE.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_DEVICE_INVALIDATED</b>
            </para>
          </description>
          <description>
            <para>The audio endpoint device has been unplugged, or the audio hardware or associated hardware resources have been reconfigured, disabled, removed, or otherwise made unavailable for use.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_SERVICE_NOT_RUNNING</b>
            </para>
          </description>
          <description>
            <para>The Windows audio service is not running.</para>
          </description>
        </item>
      </list>
    </returns>
    <remarks>
      <para>This method provides a way for a client to determine, before calling <see cref="IAudioClient.Initialize" />, whether the audio engine supports a particular stream format.</para>
      <para>For exclusive mode, <b>IsFormatSupported</b> returns S_OK if the audio endpoint device supports the caller-specified format, or it returns AUDCLNT_E_UNSUPPORTED_FORMAT if the device does not support the format. The <i>ppClosestMatch</i> parameter can be <b>NULL</b>. If it is not <b>NULL</b>, the method writes <b>NULL</b> to <i>*ppClosestMatch</i>.</para>
      <para>For shared mode, if the audio engine supports the caller-specified format, <b>IsFormatSupported</b> sets <b>*ppClosestMatch</b> to <b>NULL</b> and returns S_OK. If the audio engine does not support the caller-specified format but does support a similar format, the method retrieves the similar format through the <i>ppClosestMatch</i> parameter and returns S_FALSE. If the audio engine does not support the caller-specified format or any similar format, the method sets  <i>*ppClosestMatch</i> to <b>NULL</b> and returns AUDCLNT_E_UNSUPPORTED_FORMAT.</para>
      <para>In shared mode, the audio engine always supports the mix format, which the client can obtain by calling the <see cref="IAudioClient.GetMixFormat" /> method. In addition, the audio engine might support similar formats that have the same sample rate and number of channels as the mix format but differ in the representation of audio sample values. The audio engine represents sample values internally as floating-point numbers, but if the caller-specified format represents sample values as integers, the audio engine typically can convert between the integer sample values and its internal floating-point representation.</para>
      <para>The audio engine might be able to support an even wider range of shared-mode formats if the installation package for the audio device includes a local effects (LFX) audio processing object (APO) that can handle format conversions. An LFX APO is a software module that performs device-specific processing of an audio stream. The audio graph builder in the Windows audio service inserts the LFX APO into the stream between each client and the audio engine. When a client calls the <b>IsFormatSupported</b> method and the method determines that an LFX APO is installed for use with the device, the method directs the query to the LFX APO, which indicates whether it supports the caller-specified format.</para>
      <para>For example, a particular LFX APO might accept a 6-channel surround sound stream from a client and convert the stream to a stereo format that can be played through headphones. Typically, an LFX APO supports only client formats with sample rates that match the sample rate of the mix format.</para>
      <para>For more information about APOs, see the white papers titled "Custom Audio Effects in Windows Vista" and "Reusing the Windows Vista Audio System Effects" at the <a href="https://www.microsoft.com/whdc/device/audio/default.mspx">Audio Device Technologies for Windows</a> website. For more information about the <b>IsFormatSupported</b> method, see <a href="https://docs.microsoft.com//windows/desktop/CoreAudio/device-formats">Device Formats</a>.</para>
    </remarks>
    <seealso cref="IAudioClient Interface" />
    <seealso cref="IAudioClient.GetMixFormat" />
    <seealso cref="IAudioClient.Initialize" />
  </member>
  <member name="IAudioClient.Reset">
    <summary>
      <para>The <b>Reset</b> method resets the audio stream.</para>
    </summary>
    <returns>
      <para>If the method succeeds, it returns S_OK. If the method succeeds and the stream was already reset, the method returns S_FALSE. If it fails, possible return codes include, but are not limited to, the values shown in the following table.</para>
      <list type="table">
        <listheader>
          <description>Return code</description>
          <description>Description</description>
        </listheader>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_NOT_INITIALIZED</b>
            </para>
          </description>
          <description>
            <para>The audio stream has not been successfully initialized.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_NOT_STOPPED</b>
            </para>
          </description>
          <description>
            <para>The audio stream was not stopped at the time the call was made.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_BUFFER_OPERATION_PENDING</b>
            </para>
          </description>
          <description>
            <para>The client is currently writing to or reading from the buffer.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_SERVICE_NOT_RUNNING</b>
            </para>
          </description>
          <description>
            <para>The Windows audio service is not running.</para>
          </description>
        </item>
      </list>
    </returns>
    <remarks>
      <para>This method requires prior initialization of the <see cref="IAudioClient" /> interface. All calls to this method will fail with the error AUDCLNT_E_NOT_INITIALIZED until the client initializes the audio stream by successfully calling the <see cref="IAudioClient.Initialize" /> method.</para>
      <para>
        <b>Reset</b> is a control method that the client calls to reset a stopped audio stream. Resetting the stream flushes all pending data and resets the audio clock stream position to 0. This method fails if it is called on a stream that is not stopped.</para>
    </remarks>
    <seealso cref="IAudioClient Interface" />
    <seealso cref="IAudioClient.Initialize" />
  </member>
  <member name="IAudioClient.SetEventHandle">
    <summary>
      <para>The <b>SetEventHandle</b> method sets the event handle that the system signals when an audio buffer is ready to be processed by the client.</para>
    </summary>
    <param name="eventHandle">
      <para>The event handle.</para>
    </param>
    <returns>
      <para>If the method succeeds, it returns S_OK. If it fails, possible return codes include, but are not limited to, the values shown in the following table.</para>
      <list type="table">
        <listheader>
          <description>Return code</description>
          <description>Description</description>
        </listheader>
        <item>
          <description>
            <para>
              <b>E_INVALIDARG</b>
            </para>
          </description>
          <description>
            <para>Parameter <i>eventHandle</i> is <b>NULL</b> or an invalid handle.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_EVENTHANDLE_NOT_EXPECTED</b>
            </para>
          </description>
          <description>
            <para>The audio stream was not initialized for event-driven buffering.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_NOT_INITIALIZED</b>
            </para>
          </description>
          <description>
            <para>The audio stream has not been successfully initialized.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_DEVICE_INVALIDATED</b>
            </para>
          </description>
          <description>
            <para>The audio endpoint device has been unplugged, or the audio hardware or associated hardware resources have been reconfigured, disabled, removed, or otherwise made unavailable for use.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_SERVICE_NOT_RUNNING</b>
            </para>
          </description>
          <description>
            <para>The Windows audio service is not running.</para>
          </description>
        </item>
      </list>
    </returns>
    <remarks>
      <para>This method requires prior initialization of the <see cref="IAudioClient" /> interface. All calls to this method will fail with the error AUDCLNT_E_NOT_INITIALIZED until the client initializes the audio stream by successfully calling the <see cref="IAudioClient.Initialize" /> method.</para>
      <para>During stream initialization, the client can, as an option, enable event-driven buffering. To do so, the client calls the <see cref="IAudioClient.Initialize" /> method with the AUDCLNT_STREAMFLAGS_EVENTCALLBACK flag set. After enabling event-driven buffering, and before calling the <see cref="IAudioClient.Start" /> method to start the stream, the client must call <b>SetEventHandle</b> to register the event handle that the system will signal each time a buffer becomes ready to be processed by the client.</para>
      <para>The event handle should be in the nonsignaled state at the time that the client calls the <see cref="Start" /> method.</para>
      <para>If the client has enabled event-driven buffering of a stream, but the client calls the <see cref="Start" /> method for that stream without first calling <b>SetEventHandle</b>, the <b>Start</b> call will fail and return an error code.</para>
      <para>If the client does not enable event-driven buffering of a stream but attempts to set an event handle for the stream by calling <b>SetEventHandle</b>, the call will fail and return an error code.</para>
      <para>For a code example that calls the <b>SetEventHandle</b> method, see <a href="https://docs.microsoft.com//windows/desktop/CoreAudio/exclusive-mode-streams">Exclusive-Mode Streams</a>.</para>
    </remarks>
    <seealso cref="IAudioClient Interface" />
    <seealso cref="IAudioClient.Initialize" />
    <seealso cref="IAudioClient.Start" />
  </member>
  <member name="IAudioClient.Start">
    <summary>
      <para>The <b>Start</b> method starts the audio stream.</para>
    </summary>
    <returns>
      <para>If the method succeeds, it returns S_OK. If it fails, possible return codes include, but are not limited to, the values shown in the following table.</para>
      <list type="table">
        <listheader>
          <description>Return code</description>
          <description>Description</description>
        </listheader>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_NOT_INITIALIZED</b>
            </para>
          </description>
          <description>
            <para>The audio stream has not been successfully initialized.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_NOT_STOPPED</b>
            </para>
          </description>
          <description>
            <para>The audio stream was not stopped at the time of the <see cref="Start" /> call.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_EVENTHANDLE_NOT_SET</b>
            </para>
          </description>
          <description>
            <para>The audio stream is configured to use event-driven buffering, but the caller has not called <see cref="IAudioClient.SetEventHandle" /> to set the event handle on the stream.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_DEVICE_INVALIDATED</b>
            </para>
          </description>
          <description>
            <para>The audio endpoint device has been unplugged, or the audio hardware or associated hardware resources have been reconfigured, disabled, removed, or otherwise made unavailable for use.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_SERVICE_NOT_RUNNING</b>
            </para>
          </description>
          <description>
            <para>The Windows audio service is not running.</para>
          </description>
        </item>
      </list>
    </returns>
    <remarks>
      <para>This method requires prior initialization of the <see cref="IAudioClient" /> interface. All calls to this method will fail with the error AUDCLNT_E_NOT_INITIALIZED until the client initializes the audio stream by successfully calling the <see cref="IAudioClient.Initialize" /> method.</para>
      <para>
        <b>Start</b> is a control method that the client calls to start the audio stream. Starting the stream causes the <see cref="IAudioClient" /> object to begin streaming data between the endpoint buffer and the audio engine. It also causes the stream's audio clock to resume counting from its current position.</para>
      <para>The first time this method is called following initialization of the stream, the <see cref="IAudioClient" /> object's stream position counter begins at 0. Otherwise, the clock resumes from its position at the time that the stream was last stopped. Resetting the stream forces the stream position back to 0.</para>
      <para>To avoid start-up glitches with rendering streams, clients should not call <b>Start</b> until the audio engine has been initially loaded with data by calling the <see cref="IAudioRenderClient.GetBuffer" /> and <see cref="IAudioRenderClient.ReleaseBuffer" /> methods on the rendering interface.</para>
      <para>For code examples that call the <b>Start</b> method, see the following topics:</para>
      <list type="bullet">
        <item>
          <description>
            <a href="https://docs.microsoft.com//windows/desktop/CoreAudio/rendering-a-stream">Rendering a Stream</a>
          </description>
        </item>
        <item>
          <description>
            <a href="https://docs.microsoft.com//windows/desktop/CoreAudio/capturing-a-stream">Capturing a Stream</a>
          </description>
        </item>
      </list>
    </remarks>
    <seealso cref="IAudioClient Interface" />
    <seealso cref="IAudioClient.Initialize" />
    <seealso cref="IAudioRenderClient.GetBuffer" />
    <seealso cref="IAudioRenderClient.ReleaseBuffer" />
  </member>
  <member name="IAudioClient.Stop">
    <summary>
      <para>The <b>Stop</b> method stops the audio stream.</para>
    </summary>
    <returns>
      <para>If the method succeeds and stops the stream, it returns S_OK. If the method succeeds and the stream was already stopped, the method returns S_FALSE. If it fails, possible return codes include, but are not limited to, the values shown in the following table.</para>
      <list type="table">
        <listheader>
          <description>Return code</description>
          <description>Description</description>
        </listheader>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_NOT_INITIALIZED</b>
            </para>
          </description>
          <description>
            <para>The client has not been successfully initialized.</para>
          </description>
        </item>
        <item>
          <description>
            <para>
              <b>AUDCLNT_E_SERVICE_NOT_RUNNING</b>
            </para>
          </description>
          <description>
            <para>The Windows audio service is not running.</para>
          </description>
        </item>
      </list>
    </returns>
    <remarks>
      <para>This method requires prior initialization of the <see cref="IAudioClient" /> interface. All calls to this method will fail with the error AUDCLNT_E_NOT_INITIALIZED until the client initializes the audio stream by successfully calling the <see cref="IAudioClient.Initialize" /> method.</para>
      <para>
        <b>Stop</b> is a control method that stops a running audio stream. This method stops data from streaming through the client's connection with the audio engine. Stopping the stream freezes the stream's audio clock at its current stream position. A subsequent call to <see cref="IAudioClient.Start" /> causes the stream to resume running from that position. If necessary, the client can call the <see cref="IAudioClient.Reset" /> method to reset the position while the stream is stopped.</para>
      <para>For code examples that call the <b>Stop</b> method, see the following topics:</para>
      <list type="bullet">
        <item>
          <description>
            <a href="https://docs.microsoft.com//windows/desktop/CoreAudio/rendering-a-stream">Rendering a Stream</a>
          </description>
        </item>
        <item>
          <description>
            <a href="https://docs.microsoft.com//windows/desktop/CoreAudio/capturing-a-stream">Capturing a Stream</a>
          </description>
        </item>
      </list>
    </remarks>
    <seealso cref="IAudioClient Interface" />
    <seealso cref="IAudioClient.Initialize" />
    <seealso cref="IAudioClient.Reset" />
    <seealso cref="IAudioClient.Start" />
  </member>
</doc>