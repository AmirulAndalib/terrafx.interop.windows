<?xml version="1.0" encoding="utf-8"?>
<!-- Copyright © Tanner Gooding and Contributors. Licensed under the MIT License (MIT). See License.md in the repository root for more information. -->
<!-- Ported from https://github.com/MicrosoftDocs/sdk-api/ -->
<doc>
  <member name="DML_ACTIVATION_PARAMETERIZED_RELU_OPERATOR_DESC">
    <summary>
      <para>Performs a parameterized rectified linear unit (ReLU) activation function on every element in <i>InputTensor</i>, placing the result into the corresponding element of <i>OutputTensor</i>.</para>
      <code>f(x, slope) = x,         if x &gt;= 0
              slope * x, otherwise
</code>
      <para>This operator supports in-place execution, meaning that the output tensor is permitted to alias <i>InputTensor</i> during binding.</para>
    </summary>
    <seealso cref="DML_ACTIVATION_RELU_OPERATOR_DESC" />
  </member>
  <member name="DML_ACTIVATION_PARAMETERIZED_RELU_OPERATOR_DESC.InputTensor">
    <summary>
      <para>Type: <b>const <see cref="DML_TENSOR_DESC" />*</b></para>
      <para>The input tensor to read from.</para>
    </summary>
  </member>
  <member name="DML_ACTIVATION_PARAMETERIZED_RELU_OPERATOR_DESC.SlopeTensor">
    <summary>
      <para>Type: <b>const <see cref="DML_TENSOR_DESC" />*</b></para>
      <para>A tensor containing the slope for each corresponding value of the input.</para>
    </summary>
  </member>
  <member name="DML_ACTIVATION_PARAMETERIZED_RELU_OPERATOR_DESC.OutputTensor">
    <summary>
      <para>Type: <b>const <see cref="DML_TENSOR_DESC" />*</b></para>
      <para>The output tensor to write the results to.</para>
    </summary>
  </member>
</doc>