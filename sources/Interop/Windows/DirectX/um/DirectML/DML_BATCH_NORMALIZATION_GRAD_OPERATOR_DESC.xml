<?xml version="1.0" encoding="utf-8"?>
<!-- Copyright © Tanner Gooding and Contributors. Licensed under the MIT License (MIT). See License.md in the repository root for more information. -->
<!-- Ported from https://github.com/MicrosoftDocs/sdk-api/ -->
<doc>
  <member name="DML_BATCH_NORMALIZATION_GRAD_OPERATOR_DESC">
    <summary>
      <para>Computes backpropagation gradients for <see cref="batch normalization" />. <b>DML_BATCH_NORMALIZATION_GRAD_OPERATOR_DESC</b> performs multiple computations, which are detailed in the separate output descriptions.</para>
      <para>
        <i>OutputScaleGradientTensor</i> and <i>OutputBiasGradientTensor</i> are computed using sums across the set of dimensions for which <i>MeanTensor</i>, <i>ScaleTensor</i> and <i>VarianceTensor</i> sizes equal one.</para>
    </summary>
  </member>
  <member name="DML_BATCH_NORMALIZATION_GRAD_OPERATOR_DESC.InputTensor">
    <summary>A tensor containing the input data. This is typically the same tensor that was provided as the <i>InputTensor</i> to <see cref="DML_BATCH_NORMALIZATION_OPERATOR_DESC" /> in the forward pass.</summary>
  </member>
  <member name="DML_BATCH_NORMALIZATION_GRAD_OPERATOR_DESC.InputGradientTensor">
    <summary>The incoming gradient tensor. This is typically obtained from the output of backpropagation of a preceding layer.</summary>
  </member>
  <member name="DML_BATCH_NORMALIZATION_GRAD_OPERATOR_DESC.MeanTensor">
    <summary>A tensor containing the mean data. This is typically the same tensor that was provided as the <i>MeanTensor</i> to <see cref="DML_BATCH_NORMALIZATION_OPERATOR_DESC" /> in the forward pass.</summary>
  </member>
  <member name="DML_BATCH_NORMALIZATION_GRAD_OPERATOR_DESC.VarianceTensor">
    <summary>A tensor containing the variance data. This is typically the same tensor that was provided as the <i>VarianceTensor</i> to <b>DML_OPERATOR_BATCH_NORMALIZATION</b> in the forward pass.</summary>
  </member>
  <member name="DML_BATCH_NORMALIZATION_GRAD_OPERATOR_DESC.ScaleTensor">
    <summary>A tensor containing the scale data. This is typically the same tensor that was provided as the <i>ScaleTensor</i> to <see cref="DML_BATCH_NORMALIZATION_OPERATOR_DESC" /> in the forward pass.</summary>
  </member>
  <member name="DML_BATCH_NORMALIZATION_GRAD_OPERATOR_DESC.OutputGradientTensor">
    <summary>For every corresponding value in the inputs,<code>OutputGradient = InputGradient * (Scale / sqrt(Variance + Epsilon))</code>.</summary>
  </member>
  <member name="DML_BATCH_NORMALIZATION_GRAD_OPERATOR_DESC.OutputScaleGradientTensor">
    <summary>
      <para>The following computation is done or every corresponding value in the inputs.</para>
      <para>
        <code>OutputScaleGradient = sum(InputGradient * (Input - Mean) / sqrt(Variance + Epsilon))</code>
      </para>
    </summary>
  </member>
  <member name="DML_BATCH_NORMALIZATION_GRAD_OPERATOR_DESC.OutputBiasGradientTensor">
    <summary>
      <para>The following computation is done or every corresponding value in the inputs.</para>
      <para>
        <code>OutputBiasGradient = sum(InputGradient)</code>
      </para>
    </summary>
  </member>
  <member name="DML_BATCH_NORMALIZATION_GRAD_OPERATOR_DESC.Epsilon">
    <summary>A small value added to the variance to avoid zero.</summary>
  </member>
</doc>