<?xml version="1.0" encoding="utf-8"?>
<!-- Copyright © Tanner Gooding and Contributors. Licensed under the MIT License (MIT). See License.md in the repository root for more information. -->
<!-- Ported from https://github.com/MicrosoftDocs/sdk-api/ -->
<doc>
  <member name="DML_CONVOLUTION_OPERATOR_DESC">
    <summary>
      <para>Performs a convolution of the <i>FilterTensor</i> with the <i>InputTensor</i>. This operator supports a number of standard convolution configurations. These standard configurations include forward and backward (transposed) convolution by setting the <i>Direction</i> and <i>Mode</i> fields, as well as depth-wise convolution by setting the <i>GroupCount</i> field.</para>
      <para>A summary of the steps involved: perform the convolution into the output tensor; reshape the bias to the same dimension sizes as the output tensor; add the reshaped bias tensor to the output tensor.</para>
    </summary>
  </member>
  <member name="DML_CONVOLUTION_OPERATOR_DESC.InputTensor">
    <summary>
      <para>A tensor containing the input data. The expected dimensions of the <i>InputTensor</i> are:</para>
      <list type="bullet">
        <item>
          <description>
            <code>{ BatchCount, InputChannelCount, InputWidth }</code> for 3D,</description>
        </item>
        <item>
          <description>
            <code>{ BatchCount, InputChannelCount, InputHeight, InputWidth }</code> for 4D, and</description>
        </item>
        <item>
          <description>
            <code>{ BatchCount, InputChannelCount, InputDepth, InputHeight, InputWidth }</code> for 5D.</description>
        </item>
      </list>
    </summary>
  </member>
  <member name="DML_CONVOLUTION_OPERATOR_DESC.FilterTensor">
    <summary>
      <para>A tensor containing the filter data. The expected dimensions of the <i>FilterTensor</i> are:</para>
      <list type="bullet">
        <item>
          <description>
            <code>{ FilterBatchCount, FilterChannelCount, FilterWidth }</code> for 3D,</description>
        </item>
        <item>
          <description>
            <code>{ FilterBatchCount, FilterChannelCount, FilterHeight, FilterWidth }</code> for 4D, and</description>
        </item>
        <item>
          <description>
            <code>{ FilterBatchCount, FilterChannelCount, FilterDepth, FilterHeight, FilterWidth }</code> for 5D.</description>
        </item>
      </list>
    </summary>
  </member>
  <member name="DML_CONVOLUTION_OPERATOR_DESC.BiasTensor">
    <summary>
      <para>An optional tensor containing the bias data. The bias tensor is a tensor containing data which is broadcasted across the output tensor at the end of the convolution which is added to the result. The expected dimensions of the <i>BiasTensor</i> are:</para>
      <list type="bullet">
        <item>
          <description>
            <code>{ 1, OutputChannelCount, 1 }</code> for 3D,</description>
        </item>
        <item>
          <description>
            <code>{ 1, OutputChannelCount, 1, 1 }</code> for 4D, and</description>
        </item>
        <item>
          <description>
            <code>{ 1, OutputChannelCount, 1, 1, 1 }</code> for 5D.</description>
        </item>
      </list>
      <para>For each output channel, the single bias value for that channel is added to every element in that channel of the <i>OutputTensor</i>. That is, the <i>BiasTensor</i> is broadcasted to the size of the <i>OutputTensor</i>, and what the operator returns is the summation of this broadcasted <i>BiasTensor</i> with the result from convolution.</para>
    </summary>
  </member>
  <member name="DML_CONVOLUTION_OPERATOR_DESC.OutputTensor">
    <summary>
      <para>A tensor to write the results to. The expected dimensions of the <i>OutputTensor</i> are:</para>
      <list type="bullet">
        <item>
          <description>
            <code>{ BatchCount, OutputChannelCount, OutputWidth }</code> for 3D,</description>
        </item>
        <item>
          <description>
            <code>{ BatchCount, OutputChannelCount, OutputHeight, OutputWidth }</code> for 4D, and</description>
        </item>
        <item>
          <description>
            <code>{ BatchCount, OutputChannelCount, OutputDepth, OutputHeight, OutputWidth }</code> for 5D.</description>
        </item>
      </list>
    </summary>
  </member>
  <member name="DML_CONVOLUTION_OPERATOR_DESC.Mode">
    <summary>The mode to use for the convolution operation. <see cref="DML_CONVOLUTION_MODE_CROSS_CORRELATION" /> is the behavior for required for typical inference scenarios. In contrast, <see cref="DML_CONVOLUTION_MODE_CONVOLUTION" /> flips the order of elements in each filter kernel along each spatial dimension.</summary>
  </member>
  <member name="DML_CONVOLUTION_OPERATOR_DESC.Direction">
    <summary>The direction of the convolution operation. <see cref="DML_CONVOLUTION_DIRECTION_FORWARD" /> is the primary form of convolution used for inference where a combination of <see cref="DML_CONVOLUTION_DIRECTION_FORWARD" /> and <see cref="DML_CONVOLUTION_DIRECTION_BACKWARD" /> are used during training.</summary>
  </member>
  <member name="DML_CONVOLUTION_OPERATOR_DESC.DimensionCount">
    <summary>The number of spatial dimensions for the convolution operation. Spatial dimensions are the lower dimensions of the convolution <i>FilterTensor</i>. For example, the width and height dimension are spatial dimensions of a 4D convolution filter tensor. This value also determines the size of the <i>Strides</i>, <i>Dilations</i>, <i>StartPadding</i>, <i>EndPadding</i>, and <i>OutputPadding</i> arrays. It should be set to 2 when <i>InputTensor.DimensionCount</i> is 4, and 3 when <i>InputTensor.DimensionCount</i> is 5.</summary>
  </member>
  <member name="DML_CONVOLUTION_OPERATOR_DESC.Strides">
    <summary>An array containing the strides of the convolution operation. These strides are applied to the convolution filter. They are separate from the tensor strides included in <see cref="DML_TENSOR_DESC" />.</summary>
  </member>
  <member name="DML_CONVOLUTION_OPERATOR_DESC.Dilations">
    <summary>An array containing the dilations of the convolution operation. Dilations are strides applied to the elements of the filter kernel. This has the effect of simulating a larger filter kernel by padding the internal filter kernel elements with zeros.</summary>
  </member>
  <member name="DML_CONVOLUTION_OPERATOR_DESC.StartPadding">
    <summary>An array containing the padding values to be applied to the beginning of each spatial dimension of the filter and input tensor of the convolution operation. The start padding values are interpreted according to the <i>Direction</i> field.</summary>
  </member>
  <member name="DML_CONVOLUTION_OPERATOR_DESC.EndPadding">
    <summary>An array containing the padding values to be applied to the end of each spatial dimension of the filter and input tensor of the convolution operation. The end padding values are interpreted according to the <i>Direction</i> field.</summary>
  </member>
  <member name="DML_CONVOLUTION_OPERATOR_DESC.OutputPadding">
    <summary>An array containing the output padding of the convolution operation. <i>OutputPadding</i> applies a zero padding to the result of the convolution. This padding is applied to the end of each spatial dimension of the output tensor.</summary>
  </member>
  <member name="DML_CONVOLUTION_OPERATOR_DESC.GroupCount">
    <summary>The number of groups which to divide the convolution operation up into. This can be used to achieve depth-wise convolution by setting <i>GroupCount</i> equal to the input channel count, and <i>Direction</i> equal to <see cref="DML_CONVOLUTION_DIRECTION_FORWARD" />. This divides the convolution up into a separate convolution per input channel.</summary>
  </member>
  <member name="DML_CONVOLUTION_OPERATOR_DESC.FusedActivation">
    <summary>An optional fused activation layer to apply after the convolution. For more info, see <a href="https://docs.microsoft.com//windows/ai/directml/dml-fused-activations">Using fused operators for improved performance</a>.</summary>
  </member>
</doc>