<?xml version="1.0" encoding="utf-8"?>
<!-- Copyright © Tanner Gooding and Contributors. Licensed under the MIT License (MIT). See License.md in the repository root for more information. -->
<!-- Ported from https://github.com/MicrosoftDocs/sdk-api/ -->
<doc>
  <member name="DML_MATRIX_MULTIPLY_INTEGER_OPERATOR_DESC">
    <summary>
      <para>Performs a matrix multiplication function on integer data.</para>
      <para>This operator requires the matrix multiply input tensors to be 4D, which are formatted as <code>{ BatchCount, ChannelCount, Height, Width }</code>. The matrix multiply operator will perform BatchCount * ChannelCount number of independent matrix multiplications.</para>
      <para>For example, if <i>ATensor</i> has <i>Sizes</i> of <code>{ BatchCount, ChannelCount, M, K }</code>, and <i>BTensor</i> has <i>Sizes</i> of <code>{ BatchCount, ChannelCount, K, N }</code>, and <i>OutputTensor</i> has <i>Sizes</i> of <code>{ BatchCount, ChannelCount, M, N }</code>, then the matrix multiply operator will perform BatchCount * ChannelCount independent matrix multiplications of dimensions {M,K} x {K,N} = {M,N}.</para>
    </summary>
  </member>
  <member name="DML_MATRIX_MULTIPLY_INTEGER_OPERATOR_DESC.ATensor">
    <summary>
      <para>Type: <b>const <see cref="DML_TENSOR_DESC" />*</b></para>
      <para>A tensor containing the A data. This tensor's dimensions should be <code>{ BatchCount, ChannelCount, M, K }</code>.</para>
    </summary>
  </member>
  <member name="DML_MATRIX_MULTIPLY_INTEGER_OPERATOR_DESC.AZeroPointTensor">
    <summary>
      <para>Type: _Maybenull_ <b>const <see cref="DML_TENSOR_DESC" />*</b></para>
      <para>An optional tensor containing the ATensor zero point data. The expected dimensions of the <code>AZeroPointTensor</code> are <code>{ 1, 1, 1, 1 }</code> if per tensor quantization is required, or <code>{ 1, 1, M, 1 }</code> if per-row quantization is required. These zero point values are used for dequantizing the <i>ATensor</i> values.</para>
    </summary>
  </member>
  <member name="DML_MATRIX_MULTIPLY_INTEGER_OPERATOR_DESC.BTensor">
    <summary>
      <para>Type: <b>const <see cref="DML_TENSOR_DESC" />*</b></para>
      <para>A tensor containing the B data. This tensor's dimensions should be <code>{ BatchCount, ChannelCount, K, N }</code>.</para>
    </summary>
  </member>
  <member name="DML_MATRIX_MULTIPLY_INTEGER_OPERATOR_DESC.BZeroPointTensor">
    <summary>
      <para>Type: _Maybenull_ <b>const <see cref="DML_TENSOR_DESC" />*</b></para>
      <para>An optional tensor containing the <i>BTensor</i> zero point data. The expected dimensions of the <code>BZeroPointTensor</code> are <code>{ 1, 1, 1, 1 }</code> if per tensor quantization is required, or <code>{ 1, 1, 1, N }</code> if per column quantization is required. These zero point values are used for dequantizing the BTensor values.</para>
    </summary>
  </member>
  <member name="DML_MATRIX_MULTIPLY_INTEGER_OPERATOR_DESC.OutputTensor">
    <summary>
      <para>Type: <b>const <see cref="DML_TENSOR_DESC" />*</b></para>
      <para>A tensor with which to write the results to. This tensor's dimensions are <code>{ BatchCount, ChannelCount, M, N }</code>.</para>
    </summary>
  </member>
</doc>