<?xml version="1.0" encoding="utf-8"?>
<!-- Copyright © Tanner Gooding and Contributors. Licensed under the MIT License (MIT). See License.md in the repository root for more information. -->
<!-- Ported from https://github.com/MicrosoftDocs/sdk-api/ -->
<doc>
  <member name="DML_ELEMENT_WISE_QUANTIZED_LINEAR_ADD_OPERATOR_DESC">
    <summary>
      <para>Adds every element in <i>ATensor</i> to its corresponding element in <i>BTensor</i>, placing the result into the corresponding element of <i>OutputTensor</i>. Values contained in <i>ATensor</i> and <i>BTensor</i> are dequantized using the following equation, and then added and requantized.</para>
      <blockquote>
        <para>[!IMPORTANT]
This API is available as part of the DirectML standalone redistributable package (see <a href="https://www.nuget.org/packages/microsoft.ai.directml/">Microsoft.AI.DirectML</a> version 1.6 and later. Also see <a href="https://docs.microsoft.com//windows/ai/directml/dml-version-history">DirectML version history</a>.</para>
      </blockquote>
      <code>AValue = (A - AZeroPoint) * AScale
BValue = (B - BZeroPoint) * BScale

OutputValue = AValue + BValue

// For uint8 output, Min = 0, Max = 255
// For int8 output, Min = -128, Max = 127
OutputTensor = clamp(round(OutputValue / OutputScale) + OutputZeroPoint, Min, Max)
</code>
    </summary>
    <seealso cref="DML_ELEMENT_WISE_DEQUANTIZE_LINEAR_OPERATOR_DESC" />
  </member>
  <member name="DML_ELEMENT_WISE_QUANTIZED_LINEAR_ADD_OPERATOR_DESC.ATensor">
    <summary>
      <para>Type: <b>const <see cref="DML_TENSOR_DESC" />*</b></para>
      <para>A tensor containing the left-hand-side inputs.</para>
    </summary>
  </member>
  <member name="DML_ELEMENT_WISE_QUANTIZED_LINEAR_ADD_OPERATOR_DESC.AScaleTensor">
    <summary>
      <para>Type: <b>const <see cref="DML_TENSOR_DESC" />*</b></para>
      <para>The tensor containing the desired scale factor for <i>ATensor</i>. The expected number of elements in <i>AScaleTensor</i> is 1.</para>
    </summary>
  </member>
  <member name="DML_ELEMENT_WISE_QUANTIZED_LINEAR_ADD_OPERATOR_DESC.AZeroPointTensor">
    <summary>
      <para>Type: _Maybenull_ <b>const <see cref="DML_TENSOR_DESC" />*</b></para>
      <para>The tensor containing the desired zero point for <i>ATensor</i>. The expected number of elements in <i>AZeroPointTensor</i> is 1. <i>AZeroPointTensor</i> is an optional tensor that defaults to 0 if not provided.</para>
    </summary>
  </member>
  <member name="DML_ELEMENT_WISE_QUANTIZED_LINEAR_ADD_OPERATOR_DESC.BTensor">
    <summary>
      <para>Type: <b>const <see cref="DML_TENSOR_DESC" />*</b></para>
      <para>A tensor containing the right-hand-side inputs.</para>
    </summary>
  </member>
  <member name="DML_ELEMENT_WISE_QUANTIZED_LINEAR_ADD_OPERATOR_DESC.BScaleTensor">
    <summary>
      <para>Type: <b>const <see cref="DML_TENSOR_DESC" />*</b></para>
      <para>The tensor containing the desired scale factor for <i>BTensor</i>. The expected number of elements in <i>BScaleTensor</i> is 1.</para>
    </summary>
  </member>
  <member name="DML_ELEMENT_WISE_QUANTIZED_LINEAR_ADD_OPERATOR_DESC.BZeroPointTensor">
    <summary>
      <para>Type: _Maybenull_ <b>const <see cref="DML_TENSOR_DESC" />*</b></para>
      <para>The tensor containing the desired zero point for <i>BTensor</i>. The expected number of elements in <i>BZeroPointTensor</i> is 1. <i>BZeroPointTensor</i> is an optional tensor that defaults to 0 if not provided.</para>
    </summary>
  </member>
  <member name="DML_ELEMENT_WISE_QUANTIZED_LINEAR_ADD_OPERATOR_DESC.OutputScaleTensor">
    <summary>
      <para>Type: <b>const <see cref="DML_TENSOR_DESC" />*</b></para>
      <para>The tensor containing the desired scale factor for <i>OutputTensor</i>. This is an input tensor defining the output quantization scale factor to use while quantizing the output values. The expected number of elements in <i>OutputScaleTensor</i> is 1.</para>
    </summary>
  </member>
  <member name="DML_ELEMENT_WISE_QUANTIZED_LINEAR_ADD_OPERATOR_DESC.OutputZeroPointTensor">
    <summary>
      <para>Type: _Maybenull_ <b>const <see cref="DML_TENSOR_DESC" />*</b></para>
      <para>The tensor containing the desired zero point for <i>OutputTensor</i>. This is an input tensor defining the output quantization zero point to use while quantizing the output values. The expected number of elements in <i>OutputZeroPointTensor</i> is 1. <i>OutputZeroPointTensor</i> is an optional tensor that defaults to 0 if not provided.</para>
    </summary>
  </member>
  <member name="DML_ELEMENT_WISE_QUANTIZED_LINEAR_ADD_OPERATOR_DESC.OutputTensor">
    <summary>
      <para>Type: <b>const <see cref="DML_TENSOR_DESC" />*</b></para>
      <para>The output tensor to write the results to.</para>
    </summary>
  </member>
</doc>