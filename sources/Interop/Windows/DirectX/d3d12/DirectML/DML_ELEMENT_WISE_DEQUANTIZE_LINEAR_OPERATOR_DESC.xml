<?xml version="1.0" encoding="utf-8"?>
<!-- Copyright © Tanner Gooding and Contributors. Licensed under the MIT License (MIT). See License.md in the repository root for more information. -->
<!-- Ported from https://github.com/MicrosoftDocs/sdk-api/ -->
<doc>
  <member name="DML_ELEMENT_WISE_DEQUANTIZE_LINEAR_OPERATOR_DESC">
    <summary>
      <para>Performs the following linear dequantization function on every element in <i>InputTensor</i> with respect to its corresponding element in <i>ScaleTensor</i> and <code>ZeroPointTensor</code>, placing the results in the corresponding element of <i>OutputTensor</i>.</para>
      <code>f(input, scale, zero_point) = (input - zero_point) * scale</code>
      <para>Quantization is a common way to increase performance at the cost of precision. A group of 8-bit int values can be computed faster than a group of 32-bit float values can. Dequantizing converts the encoded data back to its domain.</para>
    </summary>
  </member>
  <member name="DML_ELEMENT_WISE_DEQUANTIZE_LINEAR_OPERATOR_DESC.InputTensor">
    <summary>The tensor containing the inputs.</summary>
  </member>
  <member name="DML_ELEMENT_WISE_DEQUANTIZE_LINEAR_OPERATOR_DESC.ScaleTensor">
    <summary>The tensor containing the scales.</summary>
  </member>
  <member name="DML_ELEMENT_WISE_DEQUANTIZE_LINEAR_OPERATOR_DESC.ZeroPointTensor">
    <summary>The tensor containing the zero point that was used for quantization.</summary>
  </member>
  <member name="DML_ELEMENT_WISE_DEQUANTIZE_LINEAR_OPERATOR_DESC.OutputTensor">
    <summary>The output tensor to write the results to.</summary>
  </member>
</doc>